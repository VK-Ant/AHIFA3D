<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Generative Approach to High Fidelity 3D Reconstruction from Text Data</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" href="assets/icon.png">
</head>
<body>
    <div class="container">
        <h1>A Generative Approach to High Fidelity 3D Reconstruction from Text Data</h1>
        
        <div class="authors">
            <div class="author">
                <a href="#" class="author-name">Venkat Kumar R<sup>1</sup></a>
                <span class="author-title">AI Engineer</span>
            </div>
            <div class="author">
                <a href="#" class="author-name">Deepak Saravanan<sup>2</sup></a>
                <span class="author-title">3D Artist</span>
            </div>
        </div>
    
        
        <div class="button-container">
            <a href="https://arxiv.org/abs/2503.03664" class="button">ðŸ“„ Paper</a>
            <a href="https://github.com/VK-Ant/Text-to-3D-Reconstruction-Research" class="button">ðŸ’» Code</a>
        </div>

        <img src="assets/3d.gif" alt="Project visualization" class="main-image">

        <div class="abstract">
            <h2>Abstract</h2>
            <p>The convergence of generative artificial intelligence and advanced computer vision technologies introduces a groundbreaking approach to transforming textual descriptions into three-dimensional representations. This research proposes a fully automated pipeline that seamlessly integrates text-to-image generation, various image processing techniques, and deep learning methods for reflection removal and 3D reconstruction. By leveraging state-of-the-art generative models like Stable Diffusion, the methodology translates natural language inputs into detailed 3D models through a multi-stage workflow.</p>
            <p>The reconstruction process begins with the generation of high-quality images from textual prompts, followed by enhancement by a reinforcement learning agent and reflection removal using the Stable Delight model. Advanced image upscaling and background removal techniques are then applied to further enhance visual fidelity. These refined two-dimensional representations are subsequently transformed into volumetric 3D models using sophisticated machine learning algorithms, capturing intricate spatial relationships and geometric characteristics. This process achieves a highly structured and detailed output, ensuring that the final 3D models reflect both semantic accuracy and geometric precision.</p>
            <p>This approach addresses key challenges in generative reconstruction, such as maintaining semantic coherence, managing geometric complexity, and preserving detailed visual information. Comprehensive experimental evaluations will assess reconstruction quality, semantic accuracy, and geometric fidelity across diverse domains and varying levels of complexity. By demonstrating the potential of AI-driven 3D reconstruction techniques, this research offers significant implications for fields such as augmented reality (AR), virtual reality (VR), and digital content creation.</p>
        </div>
        
        <!-- Results section with heading and side-by-side images -->
        <div class="results-section">
            <h2>Experimental Results</h2>
            <div class="side-by-side-container">
                <img src="assets/buddha.gif" alt="Buddha 3D Model" class="side-image">
                <img src="assets/3_1.png" alt="3D Reconstruction Views" class="side-image">
            </div>
            <div class="side-by-side-container">
                <img src="assets/temple.gif" alt="Buddha 3D Model" class="side-image">
                <img src="assets/5.png" alt="3D Reconstruction Views" class="side-image">
            </div>
        </div>
        
        <!-- BibTeX section at the end of the page -->
        <div class="bibtex-section">
            <h2 class="bibtex-heading">BibTeX</h2>
            <div class="bibtex-content">@misc{r2025generativeapproachhighfidelity,
      title={A Generative Approach to High Fidelity 3D Reconstruction from Text Data}, 
      author={Venkat Kumar R and Deepak Saravanan},
      year={2025},
      eprint={2503.03664},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.03664}, 
}</div>
        </div>
    </div>
</body>
</html>
